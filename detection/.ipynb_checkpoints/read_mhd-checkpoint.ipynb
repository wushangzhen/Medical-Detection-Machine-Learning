{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -916,  -989,  -984, ...,  -945,  -946,  -983],\n",
       "        [-1024,  -947,  -981, ...,  -975,  -964, -1003],\n",
       "        [-1024,  -937, -1017, ..., -1024, -1016, -1000],\n",
       "        ...,\n",
       "        [ -999,  -970, -1024, ...,  -859, -1024,  -963],\n",
       "        [ -877, -1024, -1021, ...,  -994,  -990, -1004],\n",
       "        [ -992, -1024,  -979, ..., -1013,  -966, -1024]],\n",
       "\n",
       "       [[ -947, -1024,  -948, ..., -1024, -1006,  -957],\n",
       "        [ -916, -1024,  -964, ..., -1024,  -959,  -903],\n",
       "        [ -919,  -998, -1024, ...,  -995,  -953, -1024],\n",
       "        ...,\n",
       "        [ -974, -1024, -1024, ..., -1024,  -983, -1008],\n",
       "        [-1024, -1004,  -907, ...,  -973,  -931,  -945],\n",
       "        [ -914,  -809,  -898, ...,  -935,  -998,  -970]],\n",
       "\n",
       "       [[ -982,  -991, -1024, ..., -1000,  -936, -1024],\n",
       "        [-1006,  -984,  -990, ...,  -847,  -983, -1024],\n",
       "        [-1000, -1024,  -838, ...,  -913, -1024, -1024],\n",
       "        ...,\n",
       "        [-1024,  -961,  -912, ..., -1024,  -944, -1007],\n",
       "        [ -897, -1005,  -914, ...,  -946,  -785,  -924],\n",
       "        [-1024,  -990,  -897, ..., -1024,  -945, -1006]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -999, -1024,  -954, ..., -1001, -1024,  -899],\n",
       "        [ -965,  -973, -1024, ...,  -913,  -982,  -995],\n",
       "        [-1024,  -880,  -981, ...,  -871, -1024,  -970],\n",
       "        ...,\n",
       "        [ -600, -1024, -1024, ...,  -606,  -745,  -903],\n",
       "        [ -682, -1024,  -524, ...,  -612,  -902, -1024],\n",
       "        [ -301,  -515,  -548, ...,  -951,  -913,  -922]],\n",
       "\n",
       "       [[ -958,  -864, -1024, ...,  -958, -1024,  -936],\n",
       "        [-1024,  -914, -1024, ..., -1024,  -931,  -963],\n",
       "        [ -908, -1024, -1007, ...,  -964,  -961, -1024],\n",
       "        ...,\n",
       "        [ -857,  -761,  -860, ...,  -488,  -649,  -919],\n",
       "        [ -625,  -998, -1024, ...,  -850,  -988,  -833],\n",
       "        [ -314,  -643,  -605, ...,  -889,  -898,  -980]],\n",
       "\n",
       "       [[-1024,  -979, -1021, ..., -1024, -1024,  -938],\n",
       "        [-1002,  -980, -1024, ..., -1024,  -741,  -967],\n",
       "        [-1024,  -803,  -976, ...,  -786,  -916, -1024],\n",
       "        ...,\n",
       "        [ -718,  -700,  -806, ...,  -493,  -458,  -720],\n",
       "        [ -430,  -888,  -911, ...,  -934, -1024,  -747],\n",
       "        [ -256,  -628,  -673, ...,  -748, -1024, -1024]]], dtype=int16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "file_name = '/Users/wushangzhen/Desktop/graduate_design/test_data/000014.mhd'\n",
    "img = sitk.ReadImage(file_name)\n",
    "img_array = sitk.GetArrayFromImage(img)\n",
    "spacing = np.array(img.GetSpacing())\n",
    "img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_name,output_path,nodule):\n",
    "    itk_img = sitk.ReadImage(file_name)\n",
    "    # load the data once\n",
    "    img_array = sitk.GetArrayFromImage(itk_img) # indexes are z,y,x (notice the ordering)\n",
    "    num_z, height, width = img_array.shape      #heightXwidth constitute the transverse plane\n",
    "    origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "    spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "    # go through all nodes (why just the biggest?)\n",
    "    node_x = nodule.node_x\n",
    "    node_y = nodule.node_y\n",
    "    node_z = nodule.node_z\n",
    "    diam =  nodule.diam\n",
    "    # just keep 3 slices\n",
    "    imgs = np.ndarray([3,height,width],dtype=np.float32)\n",
    "    masks = np.ndarray([3,height,width],dtype=np.uint8)\n",
    "    center = np.array([node_x, node_y, node_z])  # nodule center\n",
    "    v_center = SITKlib.worldToVoxel(center,origin,spacing)  # nodule center in voxel space (still x,y,z ordering)\n",
    "    for i, i_z in enumerate(np.arange(int(v_center[2])-1, int(v_center[2])+2).clip(0, num_z-1)): # clip prevents going out of bounds in Z\n",
    "        mask = SITKlib.make_mask(center, diam, i_z*spacing[2]+origin[2],width, height, spacing, origin)\n",
    "        masks[i] = mask\n",
    "        imgs[i] = img_array[i_z]\n",
    "    np.save(os.path.join(output_path,\"images.npy\"),imgs)\n",
    "    np.save(os.path.join(output_path,\"masks.npy\"),masks)\n",
    "    SITKlib.show_img(imgs,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n",
      "*************\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pydicom as dicom\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import measure, morphology\n",
    "\n",
    "\n",
    "ss = 120\n",
    "def load_scan(path):\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    if slices[0].ImagePositionPatient[2] == slices[1].ImagePositionPatient[2]:\n",
    "        sec_num = 2;\n",
    "        while slices[0].ImagePositionPatient[2] == slices[sec_num].ImagePositionPatient[2]:\n",
    "            sec_num = sec_num+1;\n",
    "        slice_num = int(len(slices) / sec_num)\n",
    "        slices.sort(key = lambda x:float(x.InstanceNumber))\n",
    "        slices = slices[0:slice_num]\n",
    "        slices.sort(key = lambda x:float(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices\n",
    "\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    print 'get_pixels_hu'\n",
    "    a = np.array(image, dtype=np.int16)\n",
    "    plt.imshow(a[ss])\n",
    "    plt.show()\n",
    "    \n",
    "    return np.array(image, dtype=np.int16), np.array([slices[0].SliceThickness] + slices[0].PixelSpacing, dtype=np.float32)\n",
    "\n",
    "def binarize_per_slice(image, spacing, intensity_th=-600, sigma=1, area_th=30, eccen_th=0.99, bg_patch_size=10):\n",
    "    bw = np.zeros(image.shape, dtype=bool)\n",
    "    print image.shape\n",
    "    \n",
    "    # prepare a mask, with all corner values set to nan\n",
    "    image_size = image.shape[1]\n",
    "    grid_axis = np.linspace(-image_size/2+0.5, image_size/2-0.5, image_size)\n",
    "    x, y = np.meshgrid(grid_axis, grid_axis)\n",
    "    d = (x**2+y**2)**0.5\n",
    "    nan_mask = (d<image_size/2).astype(float)\n",
    "    nan_mask[nan_mask == 0] = np.nan\n",
    "    for i in range(image.shape[0]):\n",
    "        # Check if corner pixels are identical, if so the slice  before Gaussian filtering\n",
    "        if len(np.unique(image[i, 0:bg_patch_size, 0:bg_patch_size])) == 1:\n",
    "            current_bw = scipy.ndimage.filters.gaussian_filter(np.multiply(image[i].astype('float32'), nan_mask), sigma, truncate=2.0) < intensity_th\n",
    "        else:\n",
    "            current_bw = scipy.ndimage.filters.gaussian_filter(image[i].astype('float32'), sigma, truncate=2.0) < intensity_th\n",
    "        \n",
    "        # select proper components\n",
    "        label = measure.label(current_bw)\n",
    "        #print label.shape\n",
    "        properties = measure.regionprops(label)\n",
    "        valid_label = set()\n",
    "        for prop in properties:\n",
    "            if prop.area * spacing[1] * spacing[2] > area_th and prop.eccentricity < eccen_th:  #连通域的条件\n",
    "                valid_label.add(prop.label)\n",
    "        #print label\n",
    "        current_bw = np.in1d(label, list(valid_label)).reshape(label.shape)  #子集判定\n",
    "        bw[i] = current_bw\n",
    "    print 'binarize_per_slice'\n",
    "    plt.imshow(bw[ss])\n",
    "    plt.show()\n",
    "    return bw\n",
    "\n",
    "def all_slice_analysis(bw, spacing, cut_num=0, vol_limit=[0.68, 8.2], area_th=6e3, dist_th=62):\n",
    "    # in some cases, several top layers need to be removed first\n",
    "    if cut_num > 0:\n",
    "        bw0 = np.copy(bw)\n",
    "        bw[-cut_num:] = False\n",
    "    label = measure.label(bw, connectivity=1)\n",
    "    # remove components access to corners\n",
    "    mid = int(label.shape[2] / 2)\n",
    "    bg_label = set([label[0, 0, 0], label[0, 0, -1], label[0, -1, 0], label[0, -1, -1], \\\n",
    "                    label[-1-cut_num, 0, 0], label[-1-cut_num, 0, -1], label[-1-cut_num, -1, 0], label[-1-cut_num, -1, -1], \\\n",
    "                    label[0, 0, mid], label[0, -1, mid], label[-1-cut_num, 0, mid], label[-1-cut_num, -1, mid]])\n",
    "    for l in bg_label:\n",
    "        label[label == l] = 0\n",
    "        \n",
    "    # select components based on volume\n",
    "    properties = measure.regionprops(label)\n",
    "    for prop in properties:\n",
    "        if prop.area * spacing.prod() < vol_limit[0] * 1e6 or prop.area * spacing.prod() > vol_limit[1] * 1e6:\n",
    "            label[label == prop.label] = 0\n",
    "            \n",
    "    # prepare a distance map for further analysis\n",
    "    x_axis = np.linspace(-label.shape[1]/2+0.5, label.shape[1]/2-0.5, label.shape[1]) * spacing[1]\n",
    "    y_axis = np.linspace(-label.shape[2]/2+0.5, label.shape[2]/2-0.5, label.shape[2]) * spacing[2]\n",
    "    x, y = np.meshgrid(x_axis, y_axis)\n",
    "    d = (x**2+y**2)**0.5\n",
    "    vols = measure.regionprops(label)\n",
    "    valid_label = set()\n",
    "    # select components based on their area and distance to center axis on all slices\n",
    "    for vol in vols:\n",
    "        single_vol = label == vol.label\n",
    "        slice_area = np.zeros(label.shape[0])\n",
    "        min_distance = np.zeros(label.shape[0])\n",
    "        for i in range(label.shape[0]):\n",
    "            slice_area[i] = np.sum(single_vol[i]) * np.prod(spacing[1:3])\n",
    "            min_distance[i] = np.min(single_vol[i] * d + (1 - single_vol[i]) * np.max(d))\n",
    "        \n",
    "        if np.average([min_distance[i] for i in range(label.shape[0]) if slice_area[i] > area_th]) < dist_th:\n",
    "            valid_label.add(vol.label)\n",
    "    #print label[label>10]      \n",
    "    bw = np.in1d(label, list(valid_label)).reshape(label.shape)\n",
    "    # fill back the parts removed earlier\n",
    "    if cut_num > 0:\n",
    "        # bw1 is bw with removed slices, bw2 is a dilated version of bw, part of their intersection is returned as final mask\n",
    "        bw1 = np.copy(bw)\n",
    "        bw1[-cut_num:] = bw0[-cut_num:]\n",
    "        bw2 = np.copy(bw)\n",
    "        bw2 = scipy.ndimage.binary_dilation(bw2, iterations=cut_num)\n",
    "        bw3 = bw1 & bw2\n",
    "        label = measure.label(bw, connectivity=1)\n",
    "        label3 = measure.label(bw3, connectivity=1)\n",
    "        l_list = list(set(np.unique(label)) - {0})\n",
    "        valid_l3 = set()\n",
    "        for l in l_list:\n",
    "            indices = np.nonzero(label==l)\n",
    "            l3 = label3[indices[0][0], indices[1][0], indices[2][0]]\n",
    "            if l3 > 0:\n",
    "                valid_l3.add(l3)\n",
    "        bw = np.in1d(label3, list(valid_l3)).reshape(label3.shape)\n",
    "    print len(valid_label)\n",
    "    plt.imshow(bw[ss])\n",
    "    plt.show()\n",
    "    return bw, len(valid_label)\n",
    "\n",
    "def fill_hole(bw):\n",
    "    # fill 3d holes\n",
    "    label = measure.label(~bw)\n",
    "    # idendify corner components\n",
    "    bg_label = set([label[0, 0, 0], label[0, 0, -1], label[0, -1, 0], label[0, -1, -1], \\\n",
    "                    label[-1, 0, 0], label[-1, 0, -1], label[-1, -1, 0], label[-1, -1, -1]])\n",
    "    bw = ~np.in1d(label, list(bg_label)).reshape(label.shape)\n",
    "    print 'fill_hole'\n",
    "    plt.imshow(bw[ss])\n",
    "    plt.show()\n",
    "    return bw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def two_lung_only(bw, spacing, max_iter=22, max_ratio=4.8):    \n",
    "    def extract_main(bw, cover=0.95):\n",
    "        for i in range(bw.shape[0]):\n",
    "            current_slice = bw[i]\n",
    "            label = measure.label(current_slice)\n",
    "            properties = measure.regionprops(label)\n",
    "            properties.sort(key=lambda x: x.area, reverse=True)\n",
    "            area = [prop.area for prop in properties]\n",
    "            count = 0\n",
    "            sum = 0\n",
    "            while sum < np.sum(area)*cover:\n",
    "                sum = sum+area[count]\n",
    "                count = count+1\n",
    "            filter = np.zeros(current_slice.shape, dtype=bool)\n",
    "            for j in range(count):\n",
    "                bb = properties[j].bbox\n",
    "                filter[bb[0]:bb[2], bb[1]:bb[3]] = filter[bb[0]:bb[2], bb[1]:bb[3]] | properties[j].convex_image\n",
    "            bw[i] = bw[i] & filter\n",
    "           \n",
    "        label = measure.label(bw)\n",
    "        properties = measure.regionprops(label)\n",
    "        properties.sort(key=lambda x: x.area, reverse=True)\n",
    "        bw = label==properties[0].label\n",
    "        print 'extract_main'\n",
    "        plt.imshow(bw[ss])\n",
    "        plt.show()\n",
    "\n",
    "        return bw\n",
    "    \n",
    "    def fill_2d_hole(bw):\n",
    "        for i in range(bw.shape[0]):\n",
    "            current_slice = bw[i]\n",
    "            label = measure.label(current_slice)\n",
    "            properties = measure.regionprops(label)\n",
    "            for prop in properties:\n",
    "                bb = prop.bbox\n",
    "                current_slice[bb[0]:bb[2], bb[1]:bb[3]] = current_slice[bb[0]:bb[2], bb[1]:bb[3]] | prop.filled_image\n",
    "            bw[i] = current_slice\n",
    "        return bw\n",
    "    \n",
    "    found_flag = False\n",
    "    iter_count = 0\n",
    "    bw0 = np.copy(bw)\n",
    "    while not found_flag and iter_count < max_iter:\n",
    "        label = measure.label(bw, connectivity=2)\n",
    "        properties = measure.regionprops(label)\n",
    "        properties.sort(key=lambda x: x.area, reverse=True)\n",
    "        if len(properties) > 1 and properties[0].area/properties[1].area < max_ratio:\n",
    "            found_flag = True\n",
    "            bw1 = label == properties[0].label\n",
    "            bw2 = label == properties[1].label\n",
    "        else:\n",
    "            bw = scipy.ndimage.binary_erosion(bw)\n",
    "            iter_count = iter_count + 1\n",
    "    \n",
    "    if found_flag:\n",
    "        d1 = scipy.ndimage.morphology.distance_transform_edt(bw1 == False, sampling=spacing)\n",
    "        d2 = scipy.ndimage.morphology.distance_transform_edt(bw2 == False, sampling=spacing)\n",
    "        bw1 = bw0 & (d1 < d2)\n",
    "        bw2 = bw0 & (d1 > d2)\n",
    "                \n",
    "        bw1 = extract_main(bw1)\n",
    "        bw2 = extract_main(bw2)\n",
    "        \n",
    "    else:\n",
    "        bw1 = bw0\n",
    "        bw2 = np.zeros(bw.shape).astype('bool')\n",
    "    \n",
    "    print 'before fill_2d_hole'\n",
    "    plt.imshow(bw1[ss])\n",
    "    plt.show()    \n",
    "    bw1 = fill_2d_hole(bw1)\n",
    "    print 'after fill_2d_hole'\n",
    "    plt.imshow(bw1[ss])\n",
    "    plt.show()    \n",
    "    bw2 = fill_2d_hole(bw2)\n",
    "    bw = bw1 | bw2\n",
    "\n",
    "    return bw1, bw2, bw\n",
    "\n",
    "def step1_python(case_pixels, spacing):\n",
    "    #case = load_scan(case_path)\n",
    "    #case_pixels, spacing = get_pixels_hu(case)\n",
    "    bw = binarize_per_slice(case_pixels, spacing)\n",
    "    flag = 0\n",
    "    cut_num = 0\n",
    "    cut_step = 2\n",
    "    bw0 = np.copy(bw)\n",
    "    while flag == 0 and cut_num < bw.shape[0]:\n",
    "        bw = np.copy(bw0)\n",
    "        bw, flag = all_slice_analysis(bw, spacing, cut_num=cut_num, vol_limit=[0.68,7.5])\n",
    "        cut_num = cut_num + cut_step\n",
    "    \n",
    "    bw = fill_hole(bw) \n",
    "    #print bw\n",
    "    bw1, bw2, bw = two_lung_only(bw, spacing)\n",
    "    return case_pixels, bw1, bw2, spacing\n",
    "    \n",
    "\n",
    "#INPUT_FOLDER = '/home/liujing/Documents/lung_nodule_detection/data/'\n",
    "#patients = os.listdir(INPUT_FOLDER)\n",
    "#patients.sort()\n",
    "#case_pixels = img_array\n",
    "#case_pixels, m1, m2, spacing = step1_python(case_pixels, spacing)\n",
    "\n",
    "print \"*************\"\n",
    "#print case_pixels\n",
    "print \"*************\"\n",
    "#plt.figure()\n",
    "#ax1 = plt.subplot(1,2,1)\n",
    "#ax2 = plt.subplot(1,2,2)\n",
    "#plt.sca(ax1)\n",
    "#plt.imshow(case_pixels[80])\n",
    "#plt.sca(ax2)\n",
    "#plt.imshow((m1)[80])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # manipulate files\n",
    "import numpy as np # import numpy lib\n",
    "from scipy.io import loadmat # import scipy lib for more complex math operations \n",
    "# load .mat file  It does not be used ?? \n",
    "import h5py # used to create h5py files\n",
    "from scipy.ndimage.interpolation import zoom # Zoom an array\n",
    "from skimage import measure #skimage is a photo processing lib\n",
    "import warnings\n",
    "from scipy.ndimage.morphology import binary_dilation, generate_binary_structure\n",
    "from skimage.morphology import convex_hull_image # compute convex part\n",
    "from multiprocessing import Pool # multi process pool provide number of process \n",
    "from functools import partial # redecorate function\n",
    "#from step1 import step1_python\n",
    "import warnings\n",
    "\n",
    "def process_mask(mask):\n",
    "    convex_mask = np.copy(mask)\n",
    "    for i_layer in range(convex_mask.shape[0]):\n",
    "        mask1  = np.ascontiguousarray(mask[i_layer])\n",
    "        if np.sum(mask1)>0:\n",
    "            mask2 = convex_hull_image(mask1)\n",
    "            if np.sum(mask2)>2*np.sum(mask1):\n",
    "                mask2 = mask1\n",
    "        else:\n",
    "            mask2 = mask1\n",
    "        convex_mask[i_layer] = mask2\n",
    "    struct = generate_binary_structure(3, 1) # generate structional element \n",
    "    dilatedMask = binary_dilation(convex_mask, structure=struct, iterations=10) \n",
    "    return dilatedMask\n",
    "\n",
    "# def savenpy(id):\n",
    "id = 1\n",
    "\n",
    "def lumTrans(img):\n",
    "    lungwin = np.array([-1200.,600.])\n",
    "    newimg = (img-lungwin[0])/(lungwin[1]-lungwin[0])\n",
    "    newimg[newimg<0]=0\n",
    "    newimg[newimg>1]=1\n",
    "    newimg = (newimg*255).astype('uint8')\n",
    "    return newimg\n",
    "\n",
    "def resample(imgs, spacing, new_spacing, order = 2):\n",
    "    if len(imgs.shape)==3:\n",
    "        new_shape = np.round(imgs.shape * spacing / new_spacing)\n",
    "        true_spacing = spacing * imgs.shape / new_shape\n",
    "        resize_factor = new_shape / imgs.shape\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            imgs = zoom(imgs, resize_factor, mode = 'nearest', order=order)\n",
    "        return imgs, true_spacing\n",
    "    elif len(imgs.shape)==4:\n",
    "        n = imgs.shape[-1]\n",
    "        newimg = []\n",
    "        for i in range(n):\n",
    "            slice = imgs[:,:,:,i]\n",
    "            newslice,true_spacing = resample(slice,spacing,new_spacing)\n",
    "            newimg.append(newslice)\n",
    "        newimg=np.transpose(np.array(newimg),[1,2,3,0])\n",
    "        return newimg,true_spacing\n",
    "    else:\n",
    "        raise ValueError('wrong shape')\n",
    "\n",
    "def savenpy(id, filelist, prep_folder, data_path, spacing, use_existing=True):      \n",
    "    resolution = np.array([1, 1, 1])\n",
    "    name = filelist[id]\n",
    "    if use_existing:\n",
    "        if os.path.exists(os.path.join(prep_folder,name+'_label.npy')) and os.path.exists(os.path.join(prep_folder,name+'_clean.npy')):\n",
    "            print(name+' had been done')\n",
    "            return\n",
    "    try:\n",
    "        im, m1, m2, spacing = step1_python(case_pixels, spacing)\n",
    "        Mask = m1+m2\n",
    "        \n",
    "        newshape = np.round(np.array(Mask.shape)*spacing/resolution)\n",
    "        xx,yy,zz= np.where(Mask)\n",
    "        box = np.array([[np.min(xx),np.max(xx)],[np.min(yy),np.max(yy)],[np.min(zz),np.max(zz)]])\n",
    "        box = box*np.expand_dims(spacing,1)/np.expand_dims(resolution,1)\n",
    "        box = np.floor(box).astype('int')\n",
    "        margin = 5\n",
    "        extendbox = np.vstack([np.max([[0,0,0],box[:,0]-margin],0),np.min([newshape,box[:,1]+2*margin],axis=0).T]).T\n",
    "        extendbox = extendbox.astype('int')\n",
    "\n",
    "        convex_mask = m1\n",
    "        dm1 = process_mask(m1)\n",
    "        dm2 = process_mask(m2)\n",
    "        dilatedMask = dm1+dm2\n",
    "        Mask = m1+m2\n",
    "        extramask = dilatedMask ^ Mask\n",
    "        bone_thresh = 210\n",
    "        pad_value = 170\n",
    "\n",
    "        im[np.isnan(im)]=-2000\n",
    "        sliceim = lumTrans(im)\n",
    "        sliceim = sliceim*dilatedMask+pad_value*(1-dilatedMask).astype('uint8')\n",
    "        bones = sliceim*extramask>bone_thresh\n",
    "        sliceim[bones] = pad_value\n",
    "        # the lung greater ROI is extracted from resampled image volue (1*1*1) \n",
    "        sliceim1,_ = resample(sliceim, spacing, resolution, order=1)\n",
    "        sliceim2 = sliceim1[extendbox[0,0]:extendbox[0,1],\n",
    "                    extendbox[1,0]:extendbox[1,1],\n",
    "                    extendbox[2,0]:extendbox[2,1]]\n",
    "        sliceim = sliceim2[np.newaxis,...]\n",
    "        print('Saving preprocessing result into ./prep_results')\n",
    "        np.save(os.path.join(prep_folder,name+'_clean'),sliceim)\n",
    "        np.save(os.path.join(prep_folder,name+'_label'),np.array([[0,0,0,0]]))\n",
    "        np.save(os.path.join(prep_folder,name+'_box'),extendbox)\n",
    "        np.save(os.path.join(prep_folder,name+'_spacing'),spacing)\n",
    "        return sliceim, extendbox\n",
    "\t# we dont save that anylonger and we want the extended box returned as a varaiable so we can map the coordinated back into dicom fomat        \n",
    "    # ok i have change my mind, we still need to find save that beacause we might want process multiple patient in future.\n",
    "    except:\n",
    "        print('bug in '+name)\n",
    "        raise\n",
    "    print(name+' done')\n",
    "\n",
    "    \n",
    "def full_prep(data_path,prep_folder,spacing, n_worker = None,use_existing=True):\n",
    "    # the old version deals with batch processing and we dont actually need this\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    if not os.path.exists(prep_folder):\n",
    "        os.mkdir(prep_folder)\n",
    "\n",
    "            \n",
    "    print('starting preprocessing')\n",
    "    filelist = [f for f in os.listdir(data_path)]\n",
    "    id = 0; # say we only have 1 patient in the datapath to be processed\n",
    "    sliceim, extendbox = savenpy(id, filelist=filelist,prep_folder=prep_folder, data_path=data_path, spacing=spacing, use_existing=use_existing)\n",
    "    #return filelist, sliceim, extendbox\n",
    "\n",
    "    #sliceim, extendbox = savenpy()\n",
    "    partial_savenpy = partial(savenpy,filelist=filelist,prep_folder=prep_folder,\n",
    "                              data_path=data_path,use_existing=use_existing)\n",
    "\n",
    "    # The preprocessing takes upto 2 secs to build the image;\n",
    "    #N = len(filelist)\n",
    "    #_=pool.map(partial_savenpy,range(N))\n",
    "    #pool.close()\n",
    "    #pool.join()\n",
    "\n",
    "    # parallel processing\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    if not os.path.exists(prep_folder):\n",
    "        os.mkdir(prep_folder)\n",
    "\n",
    "\n",
    "    #print('starting preprocessing')\n",
    "    pool = Pool(n_worker) # n_worker = 8\n",
    "    #filelist = [f for f in os.listdir(data_path)] \n",
    "    #partial_savenpy = partial(savenpy, filelist=filelist, \n",
    "    #                         prep_folder=prep_folder, data_path=data_path, \n",
    "    #                          use_existing=use_existing)\n",
    "\n",
    "    N = len(filelist)\n",
    "    _=pool.map(partial_savenpy,range(N))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('end preprocessing')\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/wushangzhen/Desktop/graduate_design/test_data/'\n",
    "prep_result_path = './prep_result'\n",
    "testsplit = full_prep(datapath, prep_result_path, spacing,\n",
    "                      n_worker = 20,\n",
    "                      use_existing = False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
